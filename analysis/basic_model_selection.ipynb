{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    fbeta_score,\n",
    ")\n",
    "\n",
    "df = pd.read_csv(\"../stats/combined.csv\")\n",
    "X = df.drop([\"chr\", \"start\", \"end\", \"cnv_type\", \"BAM_CREF_SKIP\", \"BAM_CSOFT_CLIP\", \"BAM_CHARD_CLIP\", \"BAM_CPAD\", \"BAM_CEQUAL\", \"BAM_CDIFF\", \"BAM_CBACK\"], axis=1)\n",
    "lbl_e = LabelEncoder()\n",
    "y = lbl_e.fit_transform(df[\"cnv_type\"])\n",
    "\n",
    "# Podział na zbiór treningowy i testowy\n",
    "X_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-10 01:12:55,673] A new study created in memory with name: no-name-4ffb36d8-dd42-4026-b923-26b4ad45a132\n",
      "/Users/blewandowski/CNV-detection-with-ML/cnv-detection/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3, 2: 3} which is of type dict.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032256 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1768\n",
      "[LightGBM] [Info] Number of data points in the train set: 4004094, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score -2.282466\n",
      "[LightGBM] [Info] Start training from score -1.173089\n",
      "[LightGBM] [Info] Start training from score -0.530080\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-10 01:13:09,469] Trial 0 finished with value: 0.22361611448493712 and parameters: {'model_type': 'LightGBM', 'n_estimators': 60, 'max_depth': 30, 'class_weight': {0: 1, 1: 3, 2: 3}, 'log_transform': True, 'standard_scaler': True, 'undersampling': True}. Best is trial 0 with value: 0.22361611448493712.\n",
      "/Users/blewandowski/CNV-detection-with-ML/cnv-detection/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3, 2: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "/var/folders/g6/1vkdlq6j11bg56107lyg615w0000gp/T/ipykernel_42018/1018974133.py:31: RuntimeWarning: invalid value encountered in log1p\n",
      "  X_res = np.log1p(X_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.057211 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1758\n",
      "[LightGBM] [Info] Number of data points in the train set: 8570985, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score -3.146749\n",
      "[LightGBM] [Info] Start training from score -2.037372\n",
      "[LightGBM] [Info] Start training from score -0.190389\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-10 01:13:27,388] Trial 1 finished with value: 0.24116456895847774 and parameters: {'model_type': 'LightGBM', 'n_estimators': 50, 'max_depth': 20, 'class_weight': {0: 1, 1: 3, 2: 3}, 'log_transform': True, 'standard_scaler': True, 'undersampling': False}. Best is trial 1 with value: 0.24116456895847774.\n",
      "/Users/blewandowski/CNV-detection-with-ML/cnv-detection/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3, 2: 3} which is of type dict.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046205 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1758\n",
      "[LightGBM] [Info] Number of data points in the train set: 8570985, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-10 01:13:48,327] Trial 2 finished with value: 0.8813943362681701 and parameters: {'model_type': 'LightGBM', 'n_estimators': 60, 'max_depth': 100, 'class_weight': 'balanced', 'log_transform': False, 'standard_scaler': True, 'undersampling': False}. Best is trial 2 with value: 0.8813943362681701.\n",
      "/Users/blewandowski/CNV-detection-with-ML/cnv-detection/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3, 2: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2023-10-10 01:16:56,899] Trial 3 finished with value: 0.856019306408058 and parameters: {'model_type': 'XGBoost', 'n_estimators': 50, 'max_depth': 50, 'class_weight': None, 'log_transform': False, 'standard_scaler': False, 'undersampling': False}. Best is trial 2 with value: 0.8813943362681701.\n",
      "/Users/blewandowski/CNV-detection-with-ML/cnv-detection/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3, 2: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "/Users/blewandowski/CNV-detection-with-ML/cnv-detection/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [01:16:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"scale_pos_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2023-10-10 01:20:52,909] Trial 4 finished with value: 0.8555617598656159 and parameters: {'model_type': 'XGBoost', 'n_estimators': 40, 'max_depth': 100, 'class_weight': {0: 1, 1: 3, 2: 3}, 'log_transform': True, 'standard_scaler': False, 'undersampling': False}. Best is trial 2 with value: 0.8813943362681701.\n",
      "/Users/blewandowski/CNV-detection-with-ML/cnv-detection/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3, 2: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2023-10-10 01:21:29,829] Trial 5 finished with value: 0.872112069180455 and parameters: {'model_type': 'RandomForest', 'n_estimators': 40, 'max_depth': 50, 'class_weight': 'balanced', 'log_transform': False, 'standard_scaler': True, 'undersampling': True}. Best is trial 2 with value: 0.8813943362681701.\n",
      "/Users/blewandowski/CNV-detection-with-ML/cnv-detection/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3, 2: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2023-10-10 01:23:21,620] Trial 6 finished with value: 0.8667069621966799 and parameters: {'model_type': 'XGBoost', 'n_estimators': 30, 'max_depth': 80, 'class_weight': None, 'log_transform': False, 'standard_scaler': True, 'undersampling': True}. Best is trial 2 with value: 0.8813943362681701.\n",
      "/Users/blewandowski/CNV-detection-with-ML/cnv-detection/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3, 2: 3} which is of type dict.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030958 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1765\n",
      "[LightGBM] [Info] Number of data points in the train set: 4004094, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score -2.282466\n",
      "[LightGBM] [Info] Start training from score -1.173089\n",
      "[LightGBM] [Info] Start training from score -0.530080\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-10 01:23:33,343] Trial 7 finished with value: 0.8838238844387808 and parameters: {'model_type': 'LightGBM', 'n_estimators': 40, 'max_depth': 10, 'class_weight': {0: 1, 1: 3, 2: 3}, 'log_transform': True, 'standard_scaler': False, 'undersampling': True}. Best is trial 7 with value: 0.8838238844387808.\n",
      "/Users/blewandowski/CNV-detection-with-ML/cnv-detection/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3, 2: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2023-10-10 01:23:52,696] Trial 8 finished with value: 0.8794311319689303 and parameters: {'model_type': 'RandomForest', 'n_estimators': 20, 'max_depth': 30, 'class_weight': {0: 1, 1: 3, 2: 3}, 'log_transform': True, 'standard_scaler': False, 'undersampling': True}. Best is trial 7 with value: 0.8838238844387808.\n",
      "/Users/blewandowski/CNV-detection-with-ML/cnv-detection/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3, 2: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2023-10-10 01:24:29,640] Trial 9 finished with value: 0.8717792294942143 and parameters: {'model_type': 'RandomForest', 'n_estimators': 40, 'max_depth': 60, 'class_weight': 'balanced', 'log_transform': True, 'standard_scaler': False, 'undersampling': True}. Best is trial 7 with value: 0.8838238844387808.\n",
      "/Users/blewandowski/CNV-detection-with-ML/cnv-detection/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3, 2: 3} which is of type dict.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029568 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1765\n",
      "[LightGBM] [Info] Number of data points in the train set: 4004094, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score -2.282466\n",
      "[LightGBM] [Info] Start training from score -1.173089\n",
      "[LightGBM] [Info] Start training from score -0.530080\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-10 01:24:47,965] Trial 10 finished with value: 0.8838269238248437 and parameters: {'model_type': 'LightGBM', 'n_estimators': 90, 'max_depth': 10, 'class_weight': {0: 1, 1: 3, 2: 3}, 'log_transform': True, 'standard_scaler': False, 'undersampling': True}. Best is trial 10 with value: 0.8838269238248437.\n",
      "/Users/blewandowski/CNV-detection-with-ML/cnv-detection/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3, 2: 3} which is of type dict.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.037198 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1765\n",
      "[LightGBM] [Info] Number of data points in the train set: 4004094, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score -2.282466\n",
      "[LightGBM] [Info] Start training from score -1.173089\n",
      "[LightGBM] [Info] Start training from score -0.530080\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-10 01:25:07,893] Trial 11 finished with value: 0.8838121501880014 and parameters: {'model_type': 'LightGBM', 'n_estimators': 100, 'max_depth': 10, 'class_weight': {0: 1, 1: 3, 2: 3}, 'log_transform': True, 'standard_scaler': False, 'undersampling': True}. Best is trial 10 with value: 0.8838269238248437.\n",
      "/Users/blewandowski/CNV-detection-with-ML/cnv-detection/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3, 2: 3} which is of type dict.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038440 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1765\n",
      "[LightGBM] [Info] Number of data points in the train set: 4004094, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score -2.282466\n",
      "[LightGBM] [Info] Start training from score -1.173089\n",
      "[LightGBM] [Info] Start training from score -0.530080\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-10 01:25:26,251] Trial 12 finished with value: 0.8838269238248437 and parameters: {'model_type': 'LightGBM', 'n_estimators': 90, 'max_depth': 10, 'class_weight': {0: 1, 1: 3, 2: 3}, 'log_transform': True, 'standard_scaler': False, 'undersampling': True}. Best is trial 10 with value: 0.8838269238248437.\n",
      "/Users/blewandowski/CNV-detection-with-ML/cnv-detection/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3, 2: 3} which is of type dict.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032671 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1765\n",
      "[LightGBM] [Info] Number of data points in the train set: 4004094, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score -2.282466\n",
      "[LightGBM] [Info] Start training from score -1.173089\n",
      "[LightGBM] [Info] Start training from score -0.530080\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-10 01:25:44,597] Trial 13 finished with value: 0.883827084889295 and parameters: {'model_type': 'LightGBM', 'n_estimators': 90, 'max_depth': 30, 'class_weight': {0: 1, 1: 3, 2: 3}, 'log_transform': True, 'standard_scaler': False, 'undersampling': True}. Best is trial 13 with value: 0.883827084889295.\n",
      "/Users/blewandowski/CNV-detection-with-ML/cnv-detection/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3, 2: 3} which is of type dict.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030431 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1765\n",
      "[LightGBM] [Info] Number of data points in the train set: 4004094, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score -2.282466\n",
      "[LightGBM] [Info] Start training from score -1.173089\n",
      "[LightGBM] [Info] Start training from score -0.530080\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-10 01:26:02,979] Trial 14 finished with value: 0.883827084889295 and parameters: {'model_type': 'LightGBM', 'n_estimators': 90, 'max_depth': 30, 'class_weight': {0: 1, 1: 3, 2: 3}, 'log_transform': True, 'standard_scaler': False, 'undersampling': True}. Best is trial 13 with value: 0.883827084889295.\n",
      "/Users/blewandowski/CNV-detection-with-ML/cnv-detection/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3, 2: 3} which is of type dict.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033077 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1765\n",
      "[LightGBM] [Info] Number of data points in the train set: 4004094, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score -1.369557\n",
      "[LightGBM] [Info] Start training from score -1.358792\n",
      "[LightGBM] [Info] Start training from score -0.715783\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-10 01:26:20,153] Trial 15 finished with value: 0.8838288670834564 and parameters: {'model_type': 'LightGBM', 'n_estimators': 80, 'max_depth': 40, 'class_weight': None, 'log_transform': True, 'standard_scaler': False, 'undersampling': True}. Best is trial 15 with value: 0.8838288670834564.\n",
      "/Users/blewandowski/CNV-detection-with-ML/cnv-detection/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3, 2: 3} which is of type dict.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.037673 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1765\n",
      "[LightGBM] [Info] Number of data points in the train set: 4004094, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score -1.369557\n",
      "[LightGBM] [Info] Start training from score -1.358792\n",
      "[LightGBM] [Info] Start training from score -0.715783\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-10 01:26:36,185] Trial 16 finished with value: 0.8838243195249453 and parameters: {'model_type': 'LightGBM', 'n_estimators': 70, 'max_depth': 60, 'class_weight': None, 'log_transform': True, 'standard_scaler': False, 'undersampling': True}. Best is trial 15 with value: 0.8838288670834564.\n",
      "/Users/blewandowski/CNV-detection-with-ML/cnv-detection/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3, 2: 3} which is of type dict.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028756 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1765\n",
      "[LightGBM] [Info] Number of data points in the train set: 4004094, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score -1.369557\n",
      "[LightGBM] [Info] Start training from score -1.358792\n",
      "[LightGBM] [Info] Start training from score -0.715783\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-10 01:26:53,795] Trial 17 finished with value: 0.8838288670834564 and parameters: {'model_type': 'LightGBM', 'n_estimators': 80, 'max_depth': 40, 'class_weight': None, 'log_transform': True, 'standard_scaler': False, 'undersampling': True}. Best is trial 15 with value: 0.8838288670834564.\n",
      "/Users/blewandowski/CNV-detection-with-ML/cnv-detection/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3, 2: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2023-10-10 01:29:18,317] Trial 18 finished with value: 0.8595844092164064 and parameters: {'model_type': 'RandomForest', 'n_estimators': 70, 'max_depth': 40, 'class_weight': None, 'log_transform': False, 'standard_scaler': False, 'undersampling': False}. Best is trial 15 with value: 0.8838288670834564.\n",
      "/Users/blewandowski/CNV-detection-with-ML/cnv-detection/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3, 2: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2023-10-10 01:31:09,368] Trial 19 finished with value: 0.8692430648851124 and parameters: {'model_type': 'XGBoost', 'n_estimators': 70, 'max_depth': 40, 'class_weight': None, 'log_transform': True, 'standard_scaler': False, 'undersampling': True}. Best is trial 15 with value: 0.8838288670834564.\n",
      "/Users/blewandowski/CNV-detection-with-ML/cnv-detection/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3, 2: 3} which is of type dict.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029707 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1765\n",
      "[LightGBM] [Info] Number of data points in the train set: 4004094, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score -1.369557\n",
      "[LightGBM] [Info] Start training from score -1.358792\n",
      "[LightGBM] [Info] Start training from score -0.715783\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-10 01:31:26,508] Trial 20 finished with value: 0.8838288670834564 and parameters: {'model_type': 'LightGBM', 'n_estimators': 80, 'max_depth': 60, 'class_weight': None, 'log_transform': True, 'standard_scaler': False, 'undersampling': True}. Best is trial 15 with value: 0.8838288670834564.\n",
      "/Users/blewandowski/CNV-detection-with-ML/cnv-detection/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3, 2: 3} which is of type dict.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042359 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1765\n",
      "[LightGBM] [Info] Number of data points in the train set: 4004094, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score -1.369557\n",
      "[LightGBM] [Info] Start training from score -1.358792\n",
      "[LightGBM] [Info] Start training from score -0.715783\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-10 01:31:43,853] Trial 21 finished with value: 0.8838288670834564 and parameters: {'model_type': 'LightGBM', 'n_estimators': 80, 'max_depth': 70, 'class_weight': None, 'log_transform': True, 'standard_scaler': False, 'undersampling': True}. Best is trial 15 with value: 0.8838288670834564.\n",
      "/Users/blewandowski/CNV-detection-with-ML/cnv-detection/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3, 2: 3} which is of type dict.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031019 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1765\n",
      "[LightGBM] [Info] Number of data points in the train set: 4004094, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score -1.369557\n",
      "[LightGBM] [Info] Start training from score -1.358792\n",
      "[LightGBM] [Info] Start training from score -0.715783\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-10 01:32:01,155] Trial 22 finished with value: 0.8838288670834564 and parameters: {'model_type': 'LightGBM', 'n_estimators': 80, 'max_depth': 70, 'class_weight': None, 'log_transform': True, 'standard_scaler': False, 'undersampling': True}. Best is trial 15 with value: 0.8838288670834564.\n",
      "/Users/blewandowski/CNV-detection-with-ML/cnv-detection/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3, 2: 3} which is of type dict.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031819 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1765\n",
      "[LightGBM] [Info] Number of data points in the train set: 4004094, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score -1.369557\n",
      "[LightGBM] [Info] Start training from score -1.358792\n",
      "[LightGBM] [Info] Start training from score -0.715783\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-10 01:32:21,122] Trial 23 finished with value: 0.8838118914678783 and parameters: {'model_type': 'LightGBM', 'n_estimators': 100, 'max_depth': 40, 'class_weight': None, 'log_transform': True, 'standard_scaler': False, 'undersampling': True}. Best is trial 15 with value: 0.8838288670834564.\n",
      "/Users/blewandowski/CNV-detection-with-ML/cnv-detection/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3, 2: 3} which is of type dict.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030640 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1765\n",
      "[LightGBM] [Info] Number of data points in the train set: 4004094, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score -1.369557\n",
      "[LightGBM] [Info] Start training from score -1.358792\n",
      "[LightGBM] [Info] Start training from score -0.715783\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-10 01:32:38,303] Trial 24 finished with value: 0.8838288670834564 and parameters: {'model_type': 'LightGBM', 'n_estimators': 80, 'max_depth': 80, 'class_weight': None, 'log_transform': True, 'standard_scaler': False, 'undersampling': True}. Best is trial 15 with value: 0.8838288670834564.\n",
      "/Users/blewandowski/CNV-detection-with-ML/cnv-detection/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3, 2: 3} which is of type dict.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030474 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1765\n",
      "[LightGBM] [Info] Number of data points in the train set: 4004094, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score -1.369557\n",
      "[LightGBM] [Info] Start training from score -1.358792\n",
      "[LightGBM] [Info] Start training from score -0.715783\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-10 01:32:54,306] Trial 25 finished with value: 0.8838243195249453 and parameters: {'model_type': 'LightGBM', 'n_estimators': 70, 'max_depth': 50, 'class_weight': None, 'log_transform': True, 'standard_scaler': False, 'undersampling': True}. Best is trial 15 with value: 0.8838288670834564.\n",
      "/Users/blewandowski/CNV-detection-with-ML/cnv-detection/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3, 2: 3} which is of type dict.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.056544 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1758\n",
      "[LightGBM] [Info] Number of data points in the train set: 8570985, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score -2.130622\n",
      "[LightGBM] [Info] Start training from score -2.119857\n",
      "[LightGBM] [Info] Start training from score -0.272875\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-10 01:33:00,990] Trial 26 finished with value: 0.8482436161952434 and parameters: {'model_type': 'LightGBM', 'n_estimators': 10, 'max_depth': 70, 'class_weight': None, 'log_transform': False, 'standard_scaler': True, 'undersampling': False}. Best is trial 15 with value: 0.8838288670834564.\n",
      "/Users/blewandowski/CNV-detection-with-ML/cnv-detection/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3, 2: 3} which is of type dict.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029839 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1765\n",
      "[LightGBM] [Info] Number of data points in the train set: 4004094, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score -1.369557\n",
      "[LightGBM] [Info] Start training from score -1.358792\n",
      "[LightGBM] [Info] Start training from score -0.715783\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-10 01:33:17,930] Trial 27 finished with value: 0.8838288670834564 and parameters: {'model_type': 'LightGBM', 'n_estimators': 80, 'max_depth': 60, 'class_weight': None, 'log_transform': True, 'standard_scaler': False, 'undersampling': True}. Best is trial 15 with value: 0.8838288670834564.\n",
      "/Users/blewandowski/CNV-detection-with-ML/cnv-detection/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3, 2: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2023-10-10 01:34:41,083] Trial 28 finished with value: 0.8763391882254888 and parameters: {'model_type': 'RandomForest', 'n_estimators': 100, 'max_depth': 40, 'class_weight': None, 'log_transform': True, 'standard_scaler': False, 'undersampling': True}. Best is trial 15 with value: 0.8838288670834564.\n",
      "/Users/blewandowski/CNV-detection-with-ML/cnv-detection/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3, 2: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "/Users/blewandowski/CNV-detection-with-ML/cnv-detection/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [01:34:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"scale_pos_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2023-10-10 01:35:11,369] Trial 29 finished with value: 0.19222211369384126 and parameters: {'model_type': 'XGBoost', 'n_estimators': 60, 'max_depth': 20, 'class_weight': 'balanced', 'log_transform': True, 'standard_scaler': True, 'undersampling': True}. Best is trial 15 with value: 0.8838288670834564.\n",
      "/Users/blewandowski/CNV-detection-with-ML/cnv-detection/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3, 2: 3} which is of type dict.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038113 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1765\n",
      "[LightGBM] [Info] Number of data points in the train set: 4004094, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score -1.369557\n",
      "[LightGBM] [Info] Start training from score -1.358792\n",
      "[LightGBM] [Info] Start training from score -0.715783\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-10 01:35:26,096] Trial 30 finished with value: 0.8838367214151394 and parameters: {'model_type': 'LightGBM', 'n_estimators': 60, 'max_depth': 50, 'class_weight': None, 'log_transform': True, 'standard_scaler': False, 'undersampling': True}. Best is trial 30 with value: 0.8838367214151394.\n",
      "/Users/blewandowski/CNV-detection-with-ML/cnv-detection/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3, 2: 3} which is of type dict.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029119 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1765\n",
      "[LightGBM] [Info] Number of data points in the train set: 4004094, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score -1.369557\n",
      "[LightGBM] [Info] Start training from score -1.358792\n",
      "[LightGBM] [Info] Start training from score -0.715783\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-10 01:35:40,558] Trial 31 finished with value: 0.8838367214151394 and parameters: {'model_type': 'LightGBM', 'n_estimators': 60, 'max_depth': 50, 'class_weight': None, 'log_transform': True, 'standard_scaler': False, 'undersampling': True}. Best is trial 30 with value: 0.8838367214151394.\n",
      "/Users/blewandowski/CNV-detection-with-ML/cnv-detection/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3, 2: 3} which is of type dict.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032386 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1765\n",
      "[LightGBM] [Info] Number of data points in the train set: 4004094, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score -1.369557\n",
      "[LightGBM] [Info] Start training from score -1.358792\n",
      "[LightGBM] [Info] Start training from score -0.715783\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-10 01:35:55,195] Trial 32 finished with value: 0.8838367214151394 and parameters: {'model_type': 'LightGBM', 'n_estimators': 60, 'max_depth': 50, 'class_weight': None, 'log_transform': True, 'standard_scaler': False, 'undersampling': True}. Best is trial 30 with value: 0.8838367214151394.\n",
      "/Users/blewandowski/CNV-detection-with-ML/cnv-detection/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3, 2: 3} which is of type dict.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032149 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1765\n",
      "[LightGBM] [Info] Number of data points in the train set: 4004094, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score -1.369557\n",
      "[LightGBM] [Info] Start training from score -1.358792\n",
      "[LightGBM] [Info] Start training from score -0.715783\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-10 01:36:09,607] Trial 33 finished with value: 0.8838367214151394 and parameters: {'model_type': 'LightGBM', 'n_estimators': 60, 'max_depth': 50, 'class_weight': None, 'log_transform': True, 'standard_scaler': False, 'undersampling': True}. Best is trial 30 with value: 0.8838367214151394.\n",
      "/Users/blewandowski/CNV-detection-with-ML/cnv-detection/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3, 2: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "/var/folders/g6/1vkdlq6j11bg56107lyg615w0000gp/T/ipykernel_42018/1018974133.py:31: RuntimeWarning: invalid value encountered in log1p\n",
      "  X_res = np.log1p(X_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.058831 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1758\n",
      "[LightGBM] [Info] Number of data points in the train set: 8570985, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score -2.130622\n",
      "[LightGBM] [Info] Start training from score -2.119857\n",
      "[LightGBM] [Info] Start training from score -0.272875\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-10 01:36:30,045] Trial 34 finished with value: 0.19580140734942988 and parameters: {'model_type': 'LightGBM', 'n_estimators': 60, 'max_depth': 50, 'class_weight': None, 'log_transform': True, 'standard_scaler': True, 'undersampling': False}. Best is trial 30 with value: 0.8838367214151394.\n",
      "/Users/blewandowski/CNV-detection-with-ML/cnv-detection/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3, 2: 3} which is of type dict.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.058568 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1755\n",
      "[LightGBM] [Info] Number of data points in the train set: 8570985, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score -2.130622\n",
      "[LightGBM] [Info] Start training from score -2.119857\n",
      "[LightGBM] [Info] Start training from score -0.272875\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-10 01:36:48,764] Trial 35 finished with value: 0.8625456343431935 and parameters: {'model_type': 'LightGBM', 'n_estimators': 50, 'max_depth': 50, 'class_weight': None, 'log_transform': False, 'standard_scaler': False, 'undersampling': False}. Best is trial 30 with value: 0.8838367214151394.\n",
      "/Users/blewandowski/CNV-detection-with-ML/cnv-detection/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3, 2: 3} which is of type dict.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029110 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1765\n",
      "[LightGBM] [Info] Number of data points in the train set: 4004094, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-10 01:37:02,485] Trial 36 finished with value: 0.8813324828274819 and parameters: {'model_type': 'LightGBM', 'n_estimators': 50, 'max_depth': 50, 'class_weight': 'balanced', 'log_transform': True, 'standard_scaler': False, 'undersampling': True}. Best is trial 30 with value: 0.8838367214151394.\n",
      "/Users/blewandowski/CNV-detection-with-ML/cnv-detection/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3, 2: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2023-10-10 01:40:42,230] Trial 37 finished with value: 0.8653955598243425 and parameters: {'model_type': 'XGBoost', 'n_estimators': 60, 'max_depth': 80, 'class_weight': None, 'log_transform': False, 'standard_scaler': True, 'undersampling': True}. Best is trial 30 with value: 0.8838367214151394.\n",
      "/Users/blewandowski/CNV-detection-with-ML/cnv-detection/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3, 2: 3} which is of type dict.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.061567 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1755\n",
      "[LightGBM] [Info] Number of data points in the train set: 8570985, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score -2.130622\n",
      "[LightGBM] [Info] Start training from score -2.119857\n",
      "[LightGBM] [Info] Start training from score -0.272875\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-10 01:41:01,668] Trial 38 finished with value: 0.862536092821505 and parameters: {'model_type': 'LightGBM', 'n_estimators': 50, 'max_depth': 60, 'class_weight': None, 'log_transform': True, 'standard_scaler': False, 'undersampling': False}. Best is trial 30 with value: 0.8838367214151394.\n",
      "/Users/blewandowski/CNV-detection-with-ML/cnv-detection/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3, 2: 3} which is of type dict.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034219 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1768\n",
      "[LightGBM] [Info] Number of data points in the train set: 4004094, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-10 01:41:15,501] Trial 39 finished with value: 0.19222184360151207 and parameters: {'model_type': 'LightGBM', 'n_estimators': 60, 'max_depth': 20, 'class_weight': 'balanced', 'log_transform': True, 'standard_scaler': True, 'undersampling': True}. Best is trial 30 with value: 0.8838367214151394.\n",
      "/Users/blewandowski/CNV-detection-with-ML/cnv-detection/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3, 2: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2023-10-10 01:41:44,817] Trial 40 finished with value: 0.872441703882617 and parameters: {'model_type': 'RandomForest', 'n_estimators': 30, 'max_depth': 90, 'class_weight': None, 'log_transform': False, 'standard_scaler': False, 'undersampling': True}. Best is trial 30 with value: 0.8838367214151394.\n",
      "/Users/blewandowski/CNV-detection-with-ML/cnv-detection/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3, 2: 3} which is of type dict.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029362 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1765\n",
      "[LightGBM] [Info] Number of data points in the train set: 4004094, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score -1.369557\n",
      "[LightGBM] [Info] Start training from score -1.358792\n",
      "[LightGBM] [Info] Start training from score -0.715783\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-10 01:42:00,589] Trial 41 finished with value: 0.8838243195249453 and parameters: {'model_type': 'LightGBM', 'n_estimators': 70, 'max_depth': 50, 'class_weight': None, 'log_transform': True, 'standard_scaler': False, 'undersampling': True}. Best is trial 30 with value: 0.8838367214151394.\n",
      "/Users/blewandowski/CNV-detection-with-ML/cnv-detection/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3, 2: 3} which is of type dict.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032725 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1765\n",
      "[LightGBM] [Info] Number of data points in the train set: 4004094, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score -1.369557\n",
      "[LightGBM] [Info] Start training from score -1.358792\n",
      "[LightGBM] [Info] Start training from score -0.715783\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-10 01:42:15,154] Trial 42 finished with value: 0.8838367214151394 and parameters: {'model_type': 'LightGBM', 'n_estimators': 60, 'max_depth': 40, 'class_weight': None, 'log_transform': True, 'standard_scaler': False, 'undersampling': True}. Best is trial 30 with value: 0.8838367214151394.\n",
      "/Users/blewandowski/CNV-detection-with-ML/cnv-detection/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3, 2: 3} which is of type dict.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029356 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1765\n",
      "[LightGBM] [Info] Number of data points in the train set: 4004094, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score -1.369557\n",
      "[LightGBM] [Info] Start training from score -1.358792\n",
      "[LightGBM] [Info] Start training from score -0.715783\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-10 01:42:29,670] Trial 43 finished with value: 0.8838367214151394 and parameters: {'model_type': 'LightGBM', 'n_estimators': 60, 'max_depth': 50, 'class_weight': None, 'log_transform': True, 'standard_scaler': False, 'undersampling': True}. Best is trial 30 with value: 0.8838367214151394.\n",
      "/Users/blewandowski/CNV-detection-with-ML/cnv-detection/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3, 2: 3} which is of type dict.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.035865 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1765\n",
      "[LightGBM] [Info] Number of data points in the train set: 4004094, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score -1.369557\n",
      "[LightGBM] [Info] Start training from score -1.358792\n",
      "[LightGBM] [Info] Start training from score -0.715783\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-10 01:42:41,158] Trial 44 finished with value: 0.8838324483403422 and parameters: {'model_type': 'LightGBM', 'n_estimators': 40, 'max_depth': 30, 'class_weight': None, 'log_transform': True, 'standard_scaler': False, 'undersampling': True}. Best is trial 30 with value: 0.8838367214151394.\n",
      "/Users/blewandowski/CNV-detection-with-ML/cnv-detection/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3, 2: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2023-10-10 01:45:09,094] Trial 45 finished with value: 0.8664284527249789 and parameters: {'model_type': 'XGBoost', 'n_estimators': 50, 'max_depth': 60, 'class_weight': None, 'log_transform': True, 'standard_scaler': False, 'undersampling': True}. Best is trial 30 with value: 0.8838367214151394.\n",
      "/Users/blewandowski/CNV-detection-with-ML/cnv-detection/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3, 2: 3} which is of type dict.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030199 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1765\n",
      "[LightGBM] [Info] Number of data points in the train set: 4004094, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score -1.369557\n",
      "[LightGBM] [Info] Start training from score -1.358792\n",
      "[LightGBM] [Info] Start training from score -0.715783\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-10 01:45:22,586] Trial 46 finished with value: 0.8838343689297449 and parameters: {'model_type': 'LightGBM', 'n_estimators': 50, 'max_depth': 40, 'class_weight': None, 'log_transform': True, 'standard_scaler': False, 'undersampling': True}. Best is trial 30 with value: 0.8838367214151394.\n",
      "/Users/blewandowski/CNV-detection-with-ML/cnv-detection/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3, 2: 3} which is of type dict.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031785 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1765\n",
      "[LightGBM] [Info] Number of data points in the train set: 4004094, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-10 01:45:34,762] Trial 47 finished with value: 0.8813324097750904 and parameters: {'model_type': 'LightGBM', 'n_estimators': 40, 'max_depth': 70, 'class_weight': 'balanced', 'log_transform': True, 'standard_scaler': False, 'undersampling': True}. Best is trial 30 with value: 0.8838367214151394.\n",
      "/Users/blewandowski/CNV-detection-with-ML/cnv-detection/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3, 2: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2023-10-10 01:46:21,897] Trial 48 finished with value: 0.880851006346771 and parameters: {'model_type': 'RandomForest', 'n_estimators': 60, 'max_depth': 30, 'class_weight': None, 'log_transform': True, 'standard_scaler': False, 'undersampling': True}. Best is trial 30 with value: 0.8838367214151394.\n",
      "/Users/blewandowski/CNV-detection-with-ML/cnv-detection/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3, 2: 3} which is of type dict.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.058177 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1755\n",
      "[LightGBM] [Info] Number of data points in the train set: 8570985, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score -2.130622\n",
      "[LightGBM] [Info] Start training from score -2.119857\n",
      "[LightGBM] [Info] Start training from score -0.272875\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-10 01:46:46,237] Trial 49 finished with value: 0.8625457333638478 and parameters: {'model_type': 'LightGBM', 'n_estimators': 70, 'max_depth': 50, 'class_weight': None, 'log_transform': True, 'standard_scaler': False, 'undersampling': False}. Best is trial 30 with value: 0.8838367214151394.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Najlepsze hiperparametry:\n",
      "{'model_type': 'LightGBM', 'n_estimators': 60, 'max_depth': 50, 'class_weight': None, 'log_transform': True, 'standard_scaler': False, 'undersampling': True}\n",
      "Najlepsza dokładność: 0.8838367214151394\n"
     ]
    }
   ],
   "source": [
    "#Define the objective function to optimize\n",
    "results = []\n",
    "def objective(trial):\n",
    "    # Define the hyperparameters to search over\n",
    "    model_type = trial.suggest_categorical('model_type', ['RandomForest', 'LightGBM', 'XGBoost'])\n",
    "    n_estimators = trial.suggest_int('n_estimators', 10, 100, step=10)\n",
    "    max_depth = trial.suggest_int('max_depth', 10, 100, step=10)\n",
    "    class_weight = trial.suggest_categorical('class_weight', [None, 'balanced', {0: 1, 1: 3, 2: 3}])\n",
    "    log_transform = trial.suggest_categorical('log_transform', [True, False])\n",
    "    standard_scaler = trial.suggest_categorical('standard_scaler', [True, False])\n",
    "    undersampling = trial.suggest_categorical('undersampling', [True, False])\n",
    "\n",
    "    # Preprocess the data based on hyperparameters\n",
    "    if undersampling:\n",
    "        # Undersampling klas mniejszościowych (przykład)\n",
    "        count = Counter(y_train)\n",
    "        classes_resampling = {2: int(count[2] * 0.3)}\n",
    "        under = RandomUnderSampler(\n",
    "            sampling_strategy=classes_resampling, random_state=42\n",
    "        )\n",
    "        X_res, y_res = under.fit_resample(X_train, y_train)\n",
    "    else:\n",
    "        X_res, y_res = X_train, y_train\n",
    "\n",
    "    if standard_scaler:\n",
    "        scaler = StandardScaler()\n",
    "        X_res = scaler.fit_transform(X_res)\n",
    "        x_test_res = scaler.transform(x_test)\n",
    "    \n",
    "    if log_transform:\n",
    "        X_res = np.log1p(X_res)\n",
    "        x_test_res = np.log1p(x_test)\n",
    "\n",
    "\n",
    "    if model_type == 'RandomForest':\n",
    "        model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, class_weight=class_weight, random_state=42, n_jobs=-1)\n",
    "    elif model_type == 'LightGBM':\n",
    "        model = LGBMClassifier(n_estimators=n_estimators, max_depth=max_depth, class_weight=class_weight, random_state=42, n_jobs=-1)\n",
    "    elif model_type == 'XGBoost':\n",
    "        model = XGBClassifier(n_estimators=n_estimators, max_depth=max_depth, scale_pos_weight=class_weight, random_state=42, n_jobs=-1)\n",
    "\n",
    "\n",
    "    # Trenowanie modelu\n",
    "    model.fit(X_res, y_res)\n",
    "\n",
    "    # Przewidywanie na zbiorze testowym\n",
    "    if standard_scaler or log_transform:\n",
    "        y_pred = model.predict(x_test_res)\n",
    "    else:\n",
    "        y_pred = model.predict(x_test)\n",
    "    fbeta = fbeta_score(y_test, y_pred, beta = 3, average='macro')\n",
    "\n",
    "\n",
    "    results.append({\n",
    "        'model': model_type,\n",
    "        'n_estimators': n_estimators,\n",
    "        'max_depth': max_depth,\n",
    "        'class_weight': class_weight,\n",
    "        'log_transform': log_transform,\n",
    "        'standard_scaler': standard_scaler,\n",
    "        'undersampling': undersampling,\n",
    "        'fbeta': fbeta,\n",
    "        'classification_report': classification_report(y_test, y_pred, zero_division=True),\n",
    "        'confusion_matrix': confusion_matrix(y_test, y_pred)\n",
    "    })\n",
    "\n",
    "    return fbeta\n",
    "\n",
    "# Load your data and preprocess it\n",
    "# ...\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# ...\n",
    "\n",
    "# Create an Optuna study and optimize the objective function\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)  # You can adjust the number of trials\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = study.best_params\n",
    "best_accuracy = study.best_value\n",
    "\n",
    "print(\"Najlepsze hiperparametry:\")\n",
    "print(best_params)\n",
    "print(\"Najlepsza dokładność:\", best_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).to_csv(\"results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnv-detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
