{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mJupyter cannot be started. Error attempting to locate jupyter: Running cells with 'Python 3.9.13 64-bit' requires notebook package.\n",
      "Run the following command to install 'jupyter and notebook' into the Python environment. \n",
      "Command: 'python -m pip install jupyter notebook -U\n",
      "or\n",
      "conda install jupyter notebook -U'\n",
      "Click <a href='https://aka.ms/installJupyterForVSCode'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "bedtools_path = \"/usr/bin/bedtools\"\n",
    "FASTA=\"Sus_scrofa.Sscrofa11.1.dna.chromosome.1.fa\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_del = pd.DataFrame(columns = [1,2,3,4])\n",
    "df_dup = pd.DataFrame(columns = [1,2,3,4])\n",
    "pathOut = \"train/\"\n",
    "if pathOut != \"\" and pathOut.endswith(\"/\") == False:\n",
    "    pathOut += \"/\"\n",
    "out = open(pathOut + \"chrs.bed\",\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating duplication and deletion coordinates\n",
      "[[145916573 234139115  17681421 ... 234175821  81734871 239381829]]\n",
      "[1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8674/190941863.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_dup = df_dup.append(dups)\n",
      "/tmp/ipykernel_8674/190941863.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_del = df_del.append(dels)\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating duplication and deletion coordinates\")\n",
    "for fasta_file in SeqIO.parse(open(FASTA),\"fasta\"):\n",
    "    #first line is fasta ID, 1(?), length of fasta file\n",
    "    first_line = \"\\t\".join([fasta_file.id,\"1\",str(len(str(fasta_file.seq)))]) + \"\\n\"\n",
    "    out.write(first_line)\n",
    "    dup_lengths = []\n",
    "    del_lengths = []\n",
    "    #why 1000000 in cnv count? -> because we calculate it for megabase \n",
    "    max_cnv_length = 1e5\n",
    "    cnv_count = int((len(str(fasta_file.seq))/max_cnv_length)/2)  #number of cnv that can fit in data devided by two because there are two types of cnv (duplications and deletions)\n",
    "    while len(dup_lengths) < cnv_count:\n",
    "        cnv_range = random.randint(50,100000)\n",
    "        dup_lengths.append(cnv_range)\n",
    "    while len(del_lengths) < cnv_count:\n",
    "        cnv_range = random.randint(50,100000)\n",
    "        del_lengths.append(cnv_range)\n",
    "    # dodać tutaj test -> assert, że suma tych dwóch list będzie mniejsza od długości całego genomu\n",
    "    dup_start = np.random.randint(1,len(str(fasta_file.seq)), size=(1, cnv_count))[0]\n",
    "    del_start = np.random.randint(1,len(str(fasta_file.seq)), size=(1, cnv_count))[0]\n",
    "    dup_ends = [int(a + b) for a, b in zip(dup_start, dup_lengths)]\n",
    "    del_ends = [int(a + b) for a, b in zip(del_start, del_lengths)]\n",
    "    dups = pd.DataFrame({1:[fasta_file.id]*cnv_count,2:dup_start,3:dup_ends,4:dup_lengths})\n",
    "    dels = pd.DataFrame({1:[fasta_file.id]*cnv_count,2:del_start,3:del_ends,4:del_lengths})\n",
    "    #tutaj zmienić ten append\n",
    "    df_dup = df_dup.append(dups)\n",
    "    df_del = df_del.append(dels)\n",
    "out.close()\n",
    "df_dup.to_csv(pathOut + \"dup.bed\",header=False,index=False,sep=\"\\t\")\n",
    "df_del.to_csv(pathOut + \"del.bed\",header=False,index=False,sep=\"\\t\")\n",
    "os.system(bedtools_path + \" sort -i \" + pathOut + \"dup.bed | \" + bedtools_path + \" merge -i stdin > \" + pathOut + \"dup2.bed\")\n",
    "os.system(bedtools_path + \" sort -i \" + pathOut + \"del.bed | \" + bedtools_path + \" merge -i stdin > \" + pathOut + \"del2.bed\")\n",
    "os.system(\"cp \"+ pathOut + \"del2.bed \"+ pathOut + \"del3.bed\")\n",
    "os.system(\"cp \"+ pathOut + \"dup2.bed \"+ pathOut + \"dup3.bed\")\n",
    "os.system(bedtools_path + \" intersect -wa -v -a \" + pathOut + \"dup3.bed -b \" + pathOut + \"del3.bed > \" + pathOut + \"dup4.bed\")\n",
    "os.system(bedtools_path + \" intersect -wa -v -a \" + pathOut + \"del3.bed -b \" + pathOut + \"dup3.bed > \" + pathOut + \"del4.bed\")\n",
    "no_chrs = list(range(1, int(1)+1))\n",
    "chr_freq = {}\n",
    "for i in no_chrs:\n",
    "    chr_freq[i] = i/1\n",
    "no_chrs = list(range(1, int(1)+1))\n",
    "chr_freq = {}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating duplication and deletion frequencies\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating duplication and deletion frequencies\")\n",
    "print(no_chrs)\n",
    "for i in no_chrs:\n",
    "    chr_freq[i] = round(i/1,3)\n",
    "for i in [\"del\",\"dup\"]:\n",
    "    out = open(pathOut + str(i) + \"5.bed\",\"w\")\n",
    "    for line in open(pathOut + i + \"4.bed\"):\n",
    "        if i == \"del\":\n",
    "            num = random.randint(1,1)\n",
    "            out.write(line.rstrip() + \"\\tdel\\t\" + str(chr_freq[num]) + \"\\t0\\n\")\n",
    "        elif i == \"dup\":\n",
    "            num = random.randint(1,1)\n",
    "            count = np.random.choice([2,3,4,5,6,7,8,9,10], 1, p=[0.5, 0.1, 0.1, 0.05, 0.05,0.05,0.05,0.05,0.05])[0]\n",
    "            freqs = num/1\n",
    "            cp = (count*freqs) + ((1-freqs) * 1)\n",
    "            while cp == 1.0:\n",
    "                num = random.randint(1,1)\n",
    "                count = np.random.choice([2,3,4,5,6,7,8,9,10], 1, p=[0.5, 0.1, 0.1, 0.05, 0.05,0.05,0.05,0.05,0.05])[0]\n",
    "            out.write(line.rstrip() + \"\\tdup\\t\" + str(chr_freq[num]) + \"\\t\" + str(count) + \"\\n\")\n",
    "    out.close()\n",
    "    for j in chr_freq:\n",
    "        out = open(pathOut + i + \".\" + str(j) + \".bed\",\"w\")\n",
    "        for line in open(pathOut + i + \"5.bed\"):\n",
    "            if float(line.split()[4]) >= chr_freq[j]:\n",
    "                out.write(line)\n",
    "        out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing overlaps, generating total file\n",
      "Creating bedfiles for sample 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Removing overlaps, generating total file\")\n",
    "for i in no_chrs:\n",
    "    print(\"Creating bedfiles for sample \" + str(i))\n",
    "    os.system(\"bedtools makewindows -b \" + pathOut + \"chrs.bed -w 5 > \" + pathOut + \"normal.\" + str(i) + \".bed\")\n",
    "    os.system(bedtools_path + \" intersect -v -wa -a \" + pathOut + \"normal.\" + str(i) + \".bed -b \" + pathOut + \"dup.\" + str(i) + \".bed | \" + bedtools_path + \" intersect -v -wa -a stdin -b \" + pathOut + \"del.\" + str(i) + \".bed | \" + bedtools_path + \" sort -i stdin | \" + bedtools_path + \" merge -i stdin > \" + pathOut + \"normal2.\" + str(i) + \".bed\")\n",
    "    out = open(pathOut + \"normal3.\" + str(i) + \".bed\",\"w\")\n",
    "    for line in open(pathOut + \"normal2.\" + str(i) + \".bed\"):\n",
    "        out.write(line.rstrip() + \"\\tnormal\\t1\\t1\\n\")\n",
    "    out.close()\n",
    "    os.system(\"cat \" + pathOut + \"normal3.\" + str(i) + \".bed \" + pathOut + \"dup.\" + str(i) + \".bed \" + pathOut + \"del.\" + str(i) + \".bed | \" + bedtools_path + \" sort -i stdin > \" + pathOut + \"total.\" + str(i) + \".bed\")\n",
    "    os.remove(pathOut + \"normal3.\" + str(i) + \".bed\")\n",
    "    os.remove(pathOut + \"normal2.\" + str(i) + \".bed\")\n",
    "    os.remove(pathOut + \"normal.\" + str(i) + \".bed\")\n",
    "os.remove(pathOut + \"del.bed\")\n",
    "os.remove(pathOut + \"del2.bed\")\n",
    "os.remove(pathOut + \"del3.bed\")\n",
    "os.remove(pathOut + \"del4.bed\")\n",
    "os.remove(pathOut + \"del5.bed\")\n",
    "os.remove(pathOut + \"dup.bed\")\n",
    "os.remove(pathOut + \"dup2.bed\")\n",
    "os.remove(pathOut + \"dup3.bed\")\n",
    "os.remove(pathOut + \"dup4.bed\")\n",
    "os.remove(pathOut + \"dup5.bed\")\n",
    "os.remove(pathOut + \"chrs.bed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python3 dudeML.py simReads -fasta DiNV_CH01M.fa -cov 20 -d ${i}_sim -id ${i} -RL 100\n",
    "\n",
    "python3 dudeML.py winStat -i${i}_sim/total.bam -o ${i}_sim/total_50.bed -w 50 -s 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import os\n",
    "\"\"\"\n",
    "input is generated by genomeCoverageBed -d in the following format:\n",
    "CHR POS COVERAGE\n",
    "Following that, per chromosome, find the median coverage of covered bases.\n",
    "Can find median for all chromosomes or a specified set of them, one chromosome ID per line.\n",
    "\"\"\"\n",
    "os.system(bedtools_path + \" genomecov -d -ibam \" + args.INPUT + \" > dudeml_temp_covsperbase.bed\")\n",
    "print(\"Calculating median coverage\")\n",
    "test = pd.read_table(\"dudeml_temp_covsperbase.bed\",header=None)\n",
    "covs_median = {}\n",
    "splits_median = {}\n",
    "for line in open(args.CHROMOSOME):\n",
    "    i = line.split()[0].rstrip()\n",
    "    covs_median[i] = test[2][test[2] != 0][test[0] == i].median()\n",
    "    print(i,covs_median[i])\n",
    "if args.SUMMARY is not None:\n",
    "    out = open(args.SUMMARY,\"w\")\n",
    "    for i in covs_median:\n",
    "        out.write(i + \"\\t\" + str(covs_median[i]) + \"\\n\")\n",
    "    out.close()\n",
    "if args.QUIET == False:\n",
    "    print(\"Calculating relative median coverage per window\")\n",
    "chr_stats = []\n",
    "count = 0\n",
    "\"function takes in a pandas dataframe column and outputs a dataframe containing the start and end of window, as well as window coverage median and standard deviation\"\n",
    "def rolling_with_step(chr,s, window, step):\n",
    "    vert_idx_list = np.arange(1, s.size - window, step)\n",
    "    hori_idx_list = np.arange(window)\n",
    "    A, B = np.meshgrid(hori_idx_list, vert_idx_list)\n",
    "    idx_array = A + B\n",
    "    x_array = s.values[idx_array]\n",
    "    idx = list(s.index[vert_idx_list + (int(window))])\n",
    "    med = list(np.around(list(map(np.median, x_array)),4))\n",
    "    intq = list(np.around(list(map(scipy.stats.iqr, x_array)),4))\n",
    "    means = list(np.around(list(map(np.mean, x_array)),4))\n",
    "    std = list(np.around(list(map(np.std, x_array)),4))\n",
    "    return pd.DataFrame({\"chr\":chr,\"start\":vert_idx_list,\"end\":vert_idx_list + window,\"med\":med,\"iqr\":intq,\"mean\":means,\"std\":std})\n",
    "out_df = pd.DataFrame(columns=[\"chr\",\"start\",\"end\",\"med\",\"iqr\",\"mean\",\"std\"])\n",
    "\"\"\"\n",
    "For each chromosome, divide each base by the chromosome median (or total median).\n",
    "Following that, finds the median and standard deviation for windows of a given size\n",
    "\"\"\"\n",
    "for i in covs_median:\n",
    "    test_chrs = test[test[0] == i]\n",
    "    test_chrs_3 = test_chrs[2]/covs_median[i]\n",
    "    wins_step = rolling_with_step(i,test_chrs_3,args.WINDOW_SIZE-1,args.STEP_SIZE)\n",
    "    if args.QUIET == False:\n",
    "        print(\"Chromosome \" + str(i) + \" processed\")\n",
    "    out_df = pd.concat([out_df,wins_step])\n",
    "out_df['chr']=out_df['chr'].astype(str)\n",
    "out_df['start']=out_df['start'].astype(int)\n",
    "out_df['end']=out_df['end'].astype(int)\n",
    "out_df.to_csv(args.OUTPUT,sep=\"\\t\",index =False,columns=None,header=None)\n",
    "os.remove(\"dudeml_temp_covsperbase.bed\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "84e521f526d1d07bb92520010556f3b323093b9813a51cac1ce560a82f6db19e"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('cnv-ml-PZpkSAni-py3.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
